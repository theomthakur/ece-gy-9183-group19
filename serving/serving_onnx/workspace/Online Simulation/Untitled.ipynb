{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d91030d-a109-44c3-a46a-dec7c842217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import uuid\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import json\n",
    "import logging\n",
    "import requests\n",
    "from ultralytics import YOLO\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# --- Configuration ---\n",
    "TRITON_SERVER_URL = os.environ.get(\"TRITON_SERVER_URL\", \"http://129.114.26.168:8000\")\n",
    "SWIFT_CONTAINER = os.environ.get(\"SWIFT_CONTAINER\", \"object-persist-project19\")\n",
    "TEST_IMAGES_PATH = \"organized/test/images/\"\n",
    "LOG_DIR = \"/mnt/model-checkpoints/logs\"\n",
    "FEEDBACK_DIR = \"/mnt/model-checkpoints/feedback\"\n",
    "FEEDBACK_SWIFT_PATH = \"feedback/\"\n",
    "MODEL_NAME = \"chest_xray_detector\"\n",
    "LOAD_PATTERN = [int(x) for x in os.environ.get(\"LOAD_PATTERN\", \"1,2,3,5,3,2,1\").split(\",\")]\n",
    "DELAY_BETWEEN_STEPS = int(os.environ.get(\"DELAY_BETWEEN_STEPS\", \"60\"))\n",
    "REQUEST_TIMEOUT = int(os.environ.get(\"REQUEST_TIMEOUT\", \"5\"))\n",
    "\n",
    "# --- Logging setup ---\n",
    "try:\n",
    "    os.makedirs(LOG_DIR, exist_ok=True)\n",
    "    os.makedirs(FEEDBACK_DIR, exist_ok=True)\n",
    "except Exception as e:\n",
    "    print(f\"Error creating directories {LOG_DIR} or {FEEDBACK_DIR}: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=f\"{LOG_DIR}/online_data.log\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(\"online_data_simulator\")\n",
    "logger.info(\"Initializing online data simulator\")\n",
    "\n",
    "# --- Image utilities ---\n",
    "def fetch_image(image_key):\n",
    "    \"\"\"Fetch image from Chameleon Swift using rclone\"\"\"\n",
    "    try:\n",
    "        local_path = f\"/tmp/{os.path.basename(image_key)}\"\n",
    "        subprocess.run(\n",
    "            [\"rclone\", \"copyto\", f\"chi_tacc:{SWIFT_CONTAINER}/{image_key}\", local_path],\n",
    "            check=True, capture_output=True\n",
    "        )\n",
    "        with open(local_path, \"rb\") as f:\n",
    "            image_data = f.read()\n",
    "        os.remove(local_path)\n",
    "        logger.info(f\"Fetched image {image_key}\")\n",
    "        return image_data\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to fetch image {image_key}: {e}\")\n",
    "        return None\n",
    "\n",
    "def preprocess_image(image_data):\n",
    "    \"\"\"Preprocess image for Triton inference (resize to 416x416, normalize)\"\"\"\n",
    "    try:\n",
    "        img = Image.open(io.BytesIO(image_data)).convert(\"RGB\")\n",
    "        img.verify()\n",
    "        img = Image.open(io.BytesIO(image_data))\n",
    "        img = img.resize((416, 416), Image.Resampling.LANCZOS)\n",
    "        img_array = np.array(img) / 255.0\n",
    "        if random.random() < 0.05:\n",
    "            noise = np.random.normal(0, 0.01, img_array.shape)\n",
    "            img_array = np.clip(img_array + noise, 0, 1)\n",
    "            logger.info(\"Applied Gaussian noise to image\")\n",
    "        if random.random() < 0.01:\n",
    "            raise ValueError(\"Simulated corrupted image\")\n",
    "        img = Image.fromarray((img_array * 255).astype(np.uint8))\n",
    "        temp_path = f\"/tmp/{uuid.uuid4()}.png\"\n",
    "        img.save(temp_path)\n",
    "        logger.info(f\"Preprocessed image to {temp_path}\")\n",
    "        return temp_path\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Image preprocessing failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Request sending ---\n",
    "def simulate_hospital_metadata():\n",
    "    \"\"\"Generate realistic hospital metadata\"\"\"\n",
    "    metadata = {\n",
    "        \"patient_id\": str(uuid.uuid4()),\n",
    "        \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"hospital_id\": random.choice([\"HOSP001\", \"HOSP002\", \"HOSP003\", \"HOSP004\", \"HOSP005\"]),\n",
    "        \"scan_type\": random.choice([\"frontal\", \"lateral\"])\n",
    "    }\n",
    "    logger.info(f\"Generated metadata: {metadata}\")\n",
    "    return metadata\n",
    "\n",
    "def send_request(image_key):\n",
    "    \"\"\"Send image to Triton server for inference\"\"\"\n",
    "    image_data = fetch_image(image_key)\n",
    "    if image_data is None:\n",
    "        return False, None, None\n",
    "    temp_path = preprocess_image(image_data)\n",
    "    if temp_path is None:\n",
    "        return False, None, None\n",
    "    metadata = simulate_hospital_metadata()\n",
    "    try:\n",
    "        model = YOLO(f\"{TRITON_SERVER_URL}/{MODEL_NAME}\", task=\"detect\")\n",
    "        results = model(temp_path)\n",
    "        detections = [\n",
    "            {\n",
    "                \"class\": results.names[int(box.cls[0])],\n",
    "                \"confidence\": float(box.conf[0]),\n",
    "                \"box\": box.xyxy[0].tolist()\n",
    "            } for box in results[0].boxes\n",
    "        ]\n",
    "        result = {\"metadata\": metadata, \"detections\": detections}\n",
    "        image_id = os.path.basename(image_key).split(\".\")[0]\n",
    "        store_feedback(image_id, metadata, result)\n",
    "        logger.info(f\"Inference result for {image_key}: {result}\")\n",
    "        return True, result, image_id\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Triton inference failed for {image_key}: {e}\")\n",
    "        return False, None, None\n",
    "    finally:\n",
    "        if os.path.exists(temp_path):\n",
    "            os.remove(temp_path)\n",
    "\n",
    "# --- Continuous request worker ---\n",
    "def send_continuous_requests(image_keys, duration_sec):\n",
    "    \"\"\"Send requests continuously for the specified duration\"\"\"\n",
    "    start = time.time()\n",
    "    successes, failures = 0, 0\n",
    "    while time.time() - start < duration_sec:\n",
    "        image_key = random.choice(image_keys)\n",
    "        ok, result, image_id = send_request(image_key)\n",
    "        if ok:\n",
    "            successes += 1\n",
    "        else:\n",
    "            failures += 1\n",
    "        time.sleep(random.uniform(0.5, 2))\n",
    "    logger.info(f\"Worker completed: {successes} successes, {failures} failures\")\n",
    "    return successes, failures\n",
    "\n",
    "# --- Load stage runner ---\n",
    "def run_load_stage(image_keys, concurrent_workers, duration_sec):\n",
    "    \"\"\"Run a load stage with specified concurrent workers\"\"\"\n",
    "    logger.info(f\"Starting stage: {concurrent_workers} workers for {duration_sec} seconds\")\n",
    "    with ThreadPoolExecutor(max_workers=concurrent_workers) as pool:\n",
    "        futures = [pool.submit(send_continuous_requests, image_keys, duration_sec) for _ in range(concurrent_workers)]\n",
    "        total_success, total_failure = 0, 0\n",
    "        for f in futures:\n",
    "            s, f_ = f.result()\n",
    "            total_success += s\n",
    "            total_failure += f_\n",
    "    logger.info(f\"Stage done: {total_success} successes, {total_failure} failures\")\n",
    "    return total_success, total_failure\n",
    "\n",
    "# --- Feedback storage ---\n",
    "def store_feedback(image_id, metadata, result):\n",
    "    \"\"\"Store inference result and feedback in Swift and Cinder volume\"\"\"\n",
    "    try:\n",
    "        feedback_data = {\n",
    "            \"image_id\": image_id,\n",
    "            \"metadata\": metadata,\n",
    "            \"prediction\": result,\n",
    "            \"needs_review\": random.random() < 0.1\n",
    "        }\n",
    "        feedback_file = f\"{FEEDBACK_DIR}/{image_id}_feedback.json\"\n",
    "        with open(feedback_file, \"w\") as f:\n",
    "            json.dump(feedback_data, f, indent=2)\n",
    "        feedback_key = f\"{FEEDBACK_SWIFT_PATH}{image_id}_feedback.json\"\n",
    "        subprocess.run(\n",
    "            [\"rclone\", \"copyto\", feedback_file, f\"chi_tacc:{SWIFT_CONTAINER}/{feedback_key}\"],\n",
    "            check=True, capture_output=True\n",
    "        )\n",
    "        logger.info(f\"Stored feedback for {image_id}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to store feedback for {image_id}: {e}\")\n",
    "\n",
    "# --- Triton server check ---\n",
    "def check_triton_status():\n",
    "    \"\"\"Check if Triton server is running and model is ready\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{TRITON_SERVER_URL}/v2/health/ready\", timeout=REQUEST_TIMEOUT)\n",
    "        if response.status_code == 200:\n",
    "            model_response = requests.get(f\"{TRITON_SERVER_URL}/v2/models/{MODEL_NAME}\", timeout=REQUEST_TIMEOUT)\n",
    "            if model_response.status_code == 200:\n",
    "                logger.info(\"Triton server and model are ready\")\n",
    "                return True\n",
    "            else:\n",
    "                logger.error(\"Model 'chest_xray_detector' not ready\")\n",
    "                return False\n",
    "        else:\n",
    "            logger.error(\"Triton server not ready\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error checking Triton server: {e}\")\n",
    "        return False\n",
    "\n",
    "# --- List test images ---\n",
    "def list_test_images():\n",
    "    \"\"\"List test images in Swift container\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"rclone\", \"ls\", f\"chi_tacc:{SWIFT_CONTAINER}/{TEST_IMAGES_PATH}\"],\n",
    "            check=True, capture_output=True, text=True\n",
    "        )\n",
    "        image_keys = [line.split()[1] for line in result.stdout.splitlines() if line.endswith(\".png\")]\n",
    "        logger.info(f\"Found {len(image_keys)} test images in Swift\")\n",
    "        return image_keys\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to list test images: {e}\")\n",
    "        return []\n",
    "\n",
    "# --- Main runner ---\n",
    "def main():\n",
    "    \"\"\"Run the online data simulator with load pattern\"\"\"\n",
    "    logger.info(\"Starting online data simulator\")\n",
    "    logger.info(\"Waiting 10s for Triton server to be ready...\")\n",
    "    time.sleep(10)\n",
    "    if not check_triton_status():\n",
    "        logger.error(\"Aborting simulation: Triton server not available\")\n",
    "        return\n",
    "    image_keys = list_test_images()\n",
    "    if not image_keys:\n",
    "        logger.error(\"Aborting simulation: No test images found in Swift\")\n",
    "        return\n",
    "    logger.info(f\"Loaded {len(image_keys)} test images from Swift\")\n",
    "    total_success, total_failure = 0, 0\n",
    "    for load in LOAD_PATTERN:\n",
    "        s, f = run_load_stage(image_keys, load, DELAY_BETWEEN_STEPS)\n",
    "        total_success += s\n",
    "        total_failure += f\n",
    "        logger.info(f\"Total so far: {total_success} successes, {total_failure} failures\")\n",
    "    logger.info(\"Simulation complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
