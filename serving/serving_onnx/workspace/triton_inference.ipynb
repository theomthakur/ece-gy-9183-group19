{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15581d89-dca2-4765-af71-18cda275d669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-04-29 01:10:51--  https://images.unsplash.com/photo-1533473359331-0135ef1b58bf?q=80&w=2670&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\n",
      "Resolving images.unsplash.com (images.unsplash.com)... 151.101.2.208, 151.101.130.208, 151.101.66.208, ...\n",
      "Connecting to images.unsplash.com (images.unsplash.com)|151.101.2.208|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 794302 (776K) [image/jpeg]\n",
      "Saving to: ‘car_image.jpg’\n",
      "\n",
      "car_image.jpg       100%[===================>] 775.69K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2025-04-29 01:10:51 (50.9 MB/s) - ‘car_image.jpg’ saved [794302/794302]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://images.unsplash.com/photo-1533473359331-0135ef1b58bf?q=80&w=2670&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\" -O car_image.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "adccb491-6768-4bf5-a768-4703dfc06a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-04-29 01:44:28--  https://raw.githubusercontent.com/teaching-on-testbeds/serve-system-chi/refs/heads/main/workspace/input.json\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 80313 (78K) [text/plain]\n",
      "Saving to: ‘input.json’\n",
      "\n",
      "input.json          100%[===================>]  78.43K  --.-KB/s    in 0.004s  \n",
      "\n",
      "2025-04-29 01:44:28 (17.7 MB/s) - ‘input.json’ saved [80313/80313]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://raw.githubusercontent.com/teaching-on-testbeds/serve-system-chi/refs/heads/main/workspace/input.json\" -O input.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e16d3e85-35ce-4920-b829-d0e4c7d8fdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test script for connecting to Triton server and running inference with YOLOV11\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Constants\n",
    "TRITON_SERVER_URL = \"triton_server:8000\"\n",
    "MODEL_NAME = \"chest_xray_detector\"\n",
    "TEST_IMAGE_PATH = \"./car_image.jpg\"  # Update with your test image path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab760358-115d-486f-b1ed-0df0d44a0047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_server_status():\n",
    "    \"\"\"Check if Triton server is running and model is ready\"\"\"\n",
    "    try:\n",
    "        # Check server health\n",
    "        health_url = f\"http://{TRITON_SERVER_URL}/v2/health/ready\"\n",
    "        response = requests.get(health_url)\n",
    "        if response.status_code == 200:\n",
    "            print(\"✅ Triton server is ready\")\n",
    "            \n",
    "            # Check model status\n",
    "            model_url = f\"http://{TRITON_SERVER_URL}/v2/models/{MODEL_NAME}\"\n",
    "            model_response = requests.get(model_url)\n",
    "            if model_response.status_code == 200:\n",
    "                print(f\"✅ Model '{MODEL_NAME}' is available\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"❌ Model '{MODEL_NAME}' not found or not ready\")\n",
    "                return False\n",
    "        else:\n",
    "            print(\"❌ Triton server is not ready\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to server: {e}\")\n",
    "        return False\n",
    "\n",
    "def test_ultralytics_triton():\n",
    "    \"\"\"Test using the Ultralytics YOLO with Triton\"\"\"\n",
    "    print(\"\\nTesting Ultralytics YOLO with Triton...\")\n",
    "    \n",
    "    try:\n",
    "        # Load the Triton Server model - exactly as shown in the documentation\n",
    "        model = YOLO(f\"http://{TRITON_SERVER_URL}/{MODEL_NAME}\", task=\"detect\")\n",
    "        print(\"Model loaded successfully\")\n",
    "        \n",
    "        # Run inference on a test image\n",
    "        if TEST_IMAGE_PATH and TEST_IMAGE_PATH != \"/path/to/test_image.jpg\":\n",
    "            start_time = time.time()\n",
    "            results = model(TEST_IMAGE_PATH)\n",
    "            inference_time = time.time() - start_time\n",
    "            \n",
    "            print(f\"Inference completed in {inference_time:.4f} seconds\")\n",
    "            \n",
    "            # Display results\n",
    "            for i, result in enumerate(results):\n",
    "                boxes = result.boxes\n",
    "                print(f\"Found {len(boxes)} detections:\")\n",
    "                \n",
    "                for j, box in enumerate(boxes):\n",
    "                    cls = int(box.cls[0])\n",
    "                    cls_name = result.names[cls] if cls in result.names else f\"Class {cls}\"\n",
    "                    conf = float(box.conf[0])\n",
    "                    print(f\"  Detection {j+1}: {cls_name} (Confidence: {conf:.3f})\")\n",
    "        else:\n",
    "            print(\"No test image path provided. Skipping inference test.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during testing: {e}\")\n",
    "        print(\"\\nTroubleshooting tips:\")\n",
    "        print(\"1. Check that Triton server is running (try the check_server_status function)\")\n",
    "        print(\"2. Verify that the model name is correct\")\n",
    "        print(\"3. Make sure the model is properly loaded in Triton (check server logs)\")\n",
    "        print(\"4. Ensure the test image path is correct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "25ae3aee-e36d-4f3c-81d1-18688a670fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Triton server is ready\n",
      "✅ Model 'chest_xray_detector' is available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_server_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d10d0f58-244f-4600-a771-61f22ff1fd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Triton server is ready\n",
      "✅ Model 'chest_xray_detector' is available\n",
      "\n",
      "Testing Ultralytics YOLO with Triton...\n",
      "Model loaded successfully\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 66.7ms\n",
      "Speed: 2.5ms preprocess, 66.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Inference completed in 15.8551 seconds\n",
      "Found 1 detections:\n",
      "  Detection 1: class7 (Confidence: 0.873)\n"
     ]
    }
   ],
   "source": [
    "# Check server status\n",
    "if check_server_status():\n",
    "    # Run test with Ultralytics\n",
    "    test_ultralytics_triton()\n",
    "else:\n",
    "    print(\"Server check failed. Please ensure Triton server is running.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38d49ef4-9389-4a43-9412-6017094ff142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "def run_inference(image_path):\n",
    "    try:\n",
    "        model = YOLO(f\"http://{TRITON_SERVER_URL}/{MODEL_NAME}\", task=\"detect\")\n",
    "        results = model(image_path)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Inference error: {e}\")\n",
    "        return False\n",
    "\n",
    "def stress_test(num_requests=100, concurrency=10):\n",
    "    print(f\"Starting stress test: {num_requests} requests with concurrency {concurrency}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    success_count = 0\n",
    "    total_time = 0\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=concurrency) as executor:\n",
    "        futures = [executor.submit(run_inference, TEST_IMAGE_PATH) for _ in range(num_requests)]\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            result = future.result()\n",
    "            success_count += int(result)\n",
    "    \n",
    "    total_duration = time.time() - start_time\n",
    "    print(\"\\n=== Stress Test Results ===\")\n",
    "    print(f\"Total requests: {num_requests}\")\n",
    "    print(f\"Successful responses: {success_count}\")\n",
    "    print(f\"Total duration: {total_duration:.2f} seconds\")\n",
    "    print(f\"Average requests/sec: {num_requests/total_duration:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9cda94e5-755f-4b77-b214-eea28773524c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting stress test: 50 requests with concurrency 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 38.2ms\n",
      "Speed: 2.5ms preprocess, 38.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 61.1ms\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 68.4ms\n",
      "Speed: 5.2ms preprocess, 61.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 5.2ms preprocess, 68.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 73.5ms\n",
      "Speed: 4.7ms preprocess, 73.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 100.3ms\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 99.9ms\n",
      "Speed: 4.7ms preprocess, 100.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 5.2ms preprocess, 99.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 119.0ms\n",
      "Speed: 8.3ms preprocess, 119.0ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 138.8ms\n",
      "Speed: 8.0ms preprocess, 138.8ms inference, 11.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 93.5ms\n",
      "Speed: 2.6ms preprocess, 93.5ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 119.3ms\n",
      "Speed: 3.6ms preprocess, 119.3ms inference, 7.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 72.0ms\n",
      "Speed: 2.3ms preprocess, 72.0ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 71.1ms\n",
      "Speed: 2.7ms preprocess, 71.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 75.0ms\n",
      "Speed: 2.7ms preprocess, 75.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 75.7ms\n",
      "Speed: 3.1ms preprocess, 75.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 84.0ms\n",
      "Speed: 3.1ms preprocess, 84.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 100.5ms\n",
      "Speed: 2.4ms preprocess, 100.5ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 96.5ms\n",
      "Speed: 2.5ms preprocess, 96.5ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 88.2ms\n",
      "Speed: 3.6ms preprocess, 88.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 127.9ms\n",
      "Speed: 2.5ms preprocess, 127.9ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 92.6ms\n",
      "Speed: 4.7ms preprocess, 92.6ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 111.7ms\n",
      "Speed: 2.8ms preprocess, 111.7ms inference, 6.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 79.6ms\n",
      "Speed: 6.3ms preprocess, 79.6ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 63.3ms\n",
      "Speed: 3.4ms preprocess, 63.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 75.5ms\n",
      "Speed: 6.8ms preprocess, 75.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 103.1ms\n",
      "Speed: 2.6ms preprocess, 103.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 99.4ms\n",
      "Speed: 5.2ms preprocess, 99.4ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 99.9ms\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 86.1ms\n",
      "Speed: 4.5ms preprocess, 99.9ms inference, 8.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.6ms preprocess, 86.1ms inference, 6.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 110.4ms\n",
      "Speed: 2.8ms preprocess, 110.4ms inference, 6.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 79.3ms\n",
      "Speed: 6.4ms preprocess, 79.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 78.4ms\n",
      "Speed: 6.5ms preprocess, 78.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 65.3ms\n",
      "Speed: 3.4ms preprocess, 65.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 126.9ms\n",
      "Speed: 2.4ms preprocess, 126.9ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 129.0ms\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 123.2ms\n",
      "Speed: 5.3ms preprocess, 129.0ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 3.6ms preprocess, 123.2ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 114.2ms\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 150.2ms\n",
      "Speed: 2.1ms preprocess, 114.2ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 6.6ms preprocess, 150.2ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 93.9ms\n",
      "Speed: 3.5ms preprocess, 93.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 110.1ms\n",
      "Speed: 8.6ms preprocess, 110.1ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 102.4ms\n",
      "Speed: 2.7ms preprocess, 102.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 52.2ms\n",
      "Speed: 2.3ms preprocess, 52.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 108.0ms\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 92.7ms\n",
      "Speed: 3.1ms preprocess, 108.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.9ms preprocess, 92.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 83.8ms\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 102.5ms\n",
      "Speed: 2.4ms preprocess, 83.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.4ms preprocess, 102.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 78.3ms\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 70.8ms\n",
      "Speed: 3.1ms preprocess, 78.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.3ms preprocess, 70.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 42.0ms\n",
      "Speed: 10.8ms preprocess, 42.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 40.8ms\n",
      "Speed: 2.1ms preprocess, 40.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "image 1/1 /home/jovyan/work/car_image.jpg: 640x640 1 class7, 41.6ms\n",
      "Speed: 1.9ms preprocess, 41.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "=== Stress Test Results ===\n",
      "Total requests: 50\n",
      "Successful responses: 50\n",
      "Total duration: 1.93 seconds\n",
      "Average requests/sec: 25.95\n"
     ]
    }
   ],
   "source": [
    "stress_test(num_requests = 50, concurrency = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "06075ac6-cdf4-4382-b494-d34714878583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\":\"chest_xray_detector\",\"versions\":[\"1\"],\"platform\":\"onnxruntime_onnx\",\"inputs\":[{\"name\":\"images\",\"datatype\":\"FP32\",\"shape\":[-1,3,-1,-1]}],\"outputs\":[{\"name\":\"output0\",\"datatype\":\"FP32\",\"shape\":[-1,84,-1]}]}"
     ]
    }
   ],
   "source": [
    "!curl -X GET http://triton_server:8000/v2/models/chest_xray_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "da56f7d0-acd5-45ee-a620-9e34b2a6a489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created input_fixed.json\n",
      "Resized image dimensions: 504x336\n",
      "Tensor shape: [1, 3, 336, 504]\n",
      "\n",
      "Run perf_analyzer with the following command:\n",
      "perf_analyzer -u triton_server:8000 -m chest_xray_detector --input-data input_fixed.json -b 1 --shape images:1,3,336,504 --concurrency-range 8\n",
      "\n",
      "If the above dimensions don't work, try these alternatives:\n",
      "\n",
      "Alternative 1: 512x344\n",
      "Created input_alt1.json\n",
      "perf_analyzer -u triton_server:8000 -m chest_xray_detector --input-data input_alt1.json -b 1 --shape images:1,3,344,512 --concurrency-range 8\n",
      "\n",
      "Alternative 2: 496x328\n",
      "Created input_alt2.json\n",
      "perf_analyzer -u triton_server:8000 -m chest_xray_detector --input-data input_alt2.json -b 1 --shape images:1,3,328,496 --concurrency-range 8\n",
      "\n",
      "Alternative 3: 336x224\n",
      "Created input_alt3.json\n",
      "perf_analyzer -u triton_server:8000 -m chest_xray_detector --input-data input_alt3.json -b 1 --shape images:1,3,224,336 --concurrency-range 8\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def resize_and_convert(image_path='car_image.jpg', output_file='input_fixed.json'):\n",
    "    \"\"\"\n",
    "    Resizes image to be compatible with the model's expected internal dimensions\n",
    "    and creates a proper input JSON file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the image\n",
    "        img = Image.open(image_path)\n",
    "        \n",
    "        # Convert to RGB if not already\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "            \n",
    "        # Calculate dimensions that should work with the model\n",
    "        # We need dimensions that will result in 112x168 feature maps\n",
    "        # Common ONNX models often downsample by factors of 32, 16, or 8\n",
    "        # Let's try dimensions that are multiples of 8 and should produce 168 in the final dimension\n",
    "        \n",
    "        # Resize to 336x504 (should result in 112x168 when downsampled by factor of 3)\n",
    "        # This is a guess based on the error message\n",
    "        new_width, new_height = 504, 336  # Width corresponds to the 168 dimension\n",
    "        \n",
    "        # Resize image\n",
    "        resized_img = img.resize((new_width, new_height), Image.LANCZOS)\n",
    "        \n",
    "        # Convert to numpy array and normalize to 0-1 range\n",
    "        img_array = np.array(resized_img).astype(np.float32) / 255.0\n",
    "        \n",
    "        # Transpose from HWC to CHW format (height, width, channels) -> (channels, height, width)\n",
    "        img_array = np.transpose(img_array, (2, 0, 1))\n",
    "        \n",
    "        # Flatten the array for JSON serialization\n",
    "        float_data = img_array.flatten().tolist()\n",
    "        \n",
    "        # Create the input JSON\n",
    "        input_data = {\n",
    "            \"data\": [\n",
    "                {\n",
    "                    \"images\": float_data\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Write to output file\n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(input_data, f)\n",
    "        \n",
    "        print(f\"Successfully created {output_file}\")\n",
    "        print(f\"Resized image dimensions: {new_width}x{new_height}\")\n",
    "        print(f\"Tensor shape: [1, 3, {new_height}, {new_width}]\")\n",
    "        \n",
    "        # Print the command to use with perf_analyzer\n",
    "        print(\"\\nRun perf_analyzer with the following command:\")\n",
    "        print(f\"perf_analyzer -u triton_server:8000 -m chest_xray_detector --input-data {output_file} -b 1 --shape images:1,3,{new_height},{new_width} --concurrency-range 8\")\n",
    "        \n",
    "        # Option to create alternative sizes if the first one doesn't work\n",
    "        alt_sizes = [\n",
    "            (344, 512),  # Alternative 1\n",
    "            (328, 496),  # Alternative 2\n",
    "            (224, 336)   # Smaller alternative\n",
    "        ]\n",
    "        \n",
    "        print(\"\\nIf the above dimensions don't work, try these alternatives:\")\n",
    "        for i, (h, w) in enumerate(alt_sizes, 1):\n",
    "            alt_file = f\"input_alt{i}.json\"\n",
    "            alt_img = img.resize((w, h), Image.LANCZOS)\n",
    "            alt_array = np.transpose(np.array(alt_img).astype(np.float32) / 255.0, (2, 0, 1))\n",
    "            alt_data = {\"data\": [{\"images\": alt_array.flatten().tolist()}]}\n",
    "            \n",
    "            with open(alt_file, 'w') as f:\n",
    "                json.dump(alt_data, f)\n",
    "                \n",
    "            print(f\"\\nAlternative {i}: {w}x{h}\")\n",
    "            print(f\"Created {alt_file}\")\n",
    "            print(f\"perf_analyzer -u triton_server:8000 -m chest_xray_detector --input-data {alt_file} -b 1 --shape images:1,3,{h},{w} --concurrency-range 8\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{image_path}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "resize_and_convert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "826d0ead-ab7c-4798-b749-19fdd78a7fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !perf_analyzer -u triton_server:8000 -m chest_xray_detector --input-data input_fixed.json -b 1 --shape images:1,3,336,504 --concurrency-range 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870c0256-b4f8-4b26-a8c6-bb60b39cf483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a030cc35-2a69-4270-b07b-b6b6f3dbe1d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
